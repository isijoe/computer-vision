{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEBXqWQM_nxS"
      },
      "outputs": [],
      "source": [
        "# Import PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Impor matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check version\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")\n",
        "\n",
        "# Device agnostic\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCr3m_eGGCy9"
      },
      "outputs": [],
      "source": [
        "tr = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    #transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.TrivialAugmentWide(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "ts = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    #transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwzikT73nkil"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Any, Callable, Optional, Tuple\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "from torchvision.datasets.utils import download_and_extract_archive, verify_str_arg\n",
        "from torchvision.datasets import VisionDataset\n",
        "\n",
        "\n",
        "class Food101(VisionDataset):\n",
        "    \"\"\"`The Food-101 Data Set <https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/>`_.\n",
        "\n",
        "    The Food-101 is a challenging data set of 101 food categories with 101,000 images.\n",
        "    For each class, 250 manually reviewed test images are provided as well as 750 training images.\n",
        "    On purpose, the training images were not cleaned, and thus still contain some amount of noise.\n",
        "    This comes mostly in the form of intense colors and sometimes wrong labels. All images were\n",
        "    rescaled to have a maximum side length of 512 pixels.\n",
        "\n",
        "\n",
        "    Args:\n",
        "        root (string): Root directory of the dataset.\n",
        "        split (string, optional): The dataset split, supports ``\"train\"`` (default) and ``\"test\"``.\n",
        "        transform (callable, optional): A function/transform that  takes in an PIL image and returns a transformed\n",
        "            version. E.g, ``transforms.RandomCrop``.\n",
        "        target_transform (callable, optional): A function/transform that takes in the target and transforms it.\n",
        "        download (bool, optional): If True, downloads the dataset from the internet and\n",
        "            puts it in root directory. If dataset is already downloaded, it is not\n",
        "            downloaded again. Default is False.\n",
        "    \"\"\"\n",
        "\n",
        "    _URL = \"http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\"\n",
        "    _MD5 = \"85eeb15f3717b99a5da872d97d918f87\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root: str,\n",
        "        split: str = \"train\",\n",
        "        transform: Optional[Callable] = None,\n",
        "        target_transform: Optional[Callable] = None,\n",
        "        download: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
        "        self._split = verify_str_arg(split, \"split\", (\"train\", \"test\"))\n",
        "        self._base_folder = Path(self.root) / \"food-101\"\n",
        "        self._meta_folder = self._base_folder / \"meta\"\n",
        "        self._images_folder = self._base_folder / \"images\"\n",
        "\n",
        "        if download:\n",
        "            self._download()\n",
        "\n",
        "        if not self._check_exists():\n",
        "            raise RuntimeError(\"Dataset not found. You can use download=True to download it\")\n",
        "\n",
        "        self._labels = []\n",
        "        self._image_files = []\n",
        "        with open(self._meta_folder / f\"{split}.json\") as f:\n",
        "            metadata = json.loads(f.read())\n",
        "\n",
        "        self.classes = sorted(metadata.keys())\n",
        "        random.seed(42)\n",
        "        self.classes = random.sample(self.classes, 3)\n",
        "        print(self.classes)\n",
        "        self.class_to_idx = dict(zip(self.classes, range(len(self.classes))))\n",
        "        for class_label, im_rel_paths in metadata.items():\n",
        "            if class_label in self.classes:\n",
        "              self._labels += [self.class_to_idx[class_label]] * len(im_rel_paths)\n",
        "              self._image_files += [\n",
        "                  self._images_folder.joinpath(*f\"{im_rel_path}.jpg\".split(\"/\")) for im_rel_path in im_rel_paths\n",
        "              ]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._image_files)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[Any, Any]:\n",
        "        image_file, label = self._image_files[idx], self._labels[idx]\n",
        "        image = PIL.Image.open(image_file).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def extra_repr(self) -> str:\n",
        "        return f\"split={self._split}\"\n",
        "\n",
        "    def _check_exists(self) -> bool:\n",
        "        return all(folder.exists() and folder.is_dir() for folder in (self._meta_folder, self._images_folder))\n",
        "\n",
        "    def _download(self) -> None:\n",
        "        if self._check_exists():\n",
        "            return\n",
        "        download_and_extract_archive(self._URL, download_root=self.root, md5=self._MD5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2JFQWJnp7r4"
      },
      "outputs": [],
      "source": [
        "train_data = Food101(\n",
        "    root=\"data\",\n",
        "    split=\"train\",\n",
        "    download=True,\n",
        "    transform=tr,\n",
        "    target_transform=None\n",
        ")\n",
        "test_data = Food101(\n",
        "    root=\"data\",\n",
        "    split=\"test\",\n",
        "    download=True,\n",
        "    transform=ts\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgDMWGDqCCPn"
      },
      "outputs": [],
      "source": [
        "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")\n",
        "print(f\"Train data classes: {train_data.classes}\")\n",
        "print(f\"Test data classes: {test_data.classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5JyeFIOX64k"
      },
      "outputs": [],
      "source": [
        "indices = torch.arange(10000)\n",
        "indices2 = torch.arange(2000)\n",
        "train_data2 = torch.utils.data.Subset(train_data, indices)\n",
        "test_data2 = torch.utils.data.Subset(test_data, indices2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVeg2HqJA0Rw"
      },
      "outputs": [],
      "source": [
        "image, label = train_data[0]\n",
        "print(f\"Image shape: {image.shape}, Label shape: {label}\")\n",
        "class_names = train_data.classes\n",
        "print(f\"Class names: {class_names}\")\n",
        "plt.imshow(image.permute(1,2,0))\n",
        "plt.title(class_names[label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z3t-750DAwD"
      },
      "outputs": [],
      "source": [
        "# Plot more images\n",
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows * cols + 1):\n",
        "  random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "  img, label = train_data[random_idx]\n",
        "  fig.add_subplot(rows, cols, i)\n",
        "  plt.imshow(img.permute(1,2,0))\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLwcj-H0DxHr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup the batch size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Turn datasets into iterables (batches)\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=os.cpu_count(),\n",
        "    pin_memory=True\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=os.cpu_count(),\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Check out dataloader lengths\n",
        "print(f\"Dataloader: {train_dataloader, test_dataloader}\")\n",
        "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
        "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\n",
        "\n",
        "# Check out what's inside the training dataloader\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "print(f\"Features batch shape: {train_features_batch.shape}, Labels batch shape: {train_labels_batch.shape}\")\n",
        "\n",
        "# Show a sample\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.permute(1,2,0))\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False);\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}, label size: {label.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95M6Q16fHndr"
      },
      "outputs": [],
      "source": [
        "class VGG(nn.Module):\n",
        "  def __init__(self, in_shape: int, hidden_units: int, out_shape: int):\n",
        "    super().__init__()\n",
        "    self.block1 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels=in_shape,\n",
        "            out_channels=hidden_units,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(\n",
        "            in_channels=hidden_units,\n",
        "            out_channels=hidden_units*4,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.block2 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels=hidden_units*4,\n",
        "            out_channels=hidden_units*8,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(\n",
        "            in_channels=hidden_units*8,\n",
        "            out_channels=hidden_units*8,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.block3 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels=hidden_units*8,\n",
        "            out_channels=hidden_units*4,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(\n",
        "            in_channels=hidden_units*4,\n",
        "            out_channels=hidden_units,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*8*8, out_features=out_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    return self.classifier(self.block3(self.block2(self.block1(x))))\n",
        "    #return self.classifier(self.block2(self.block1(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak4ZWUydJcXy"
      },
      "outputs": [],
      "source": [
        "model_0 = VGG(\n",
        "    in_shape=3,\n",
        "    hidden_units=8,\n",
        "    out_shape=len(class_names)\n",
        ")\n",
        "print(model_0.to(device))\n",
        "print(f\"Model on Device: {next(model_0.parameters()).device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_A82QmPQd4f"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(size=(1,3,64,64)).to(device)\n",
        "x = model_0(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyFnC4bUJ5vV"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def train_time(start: float, end: float, device: torch.device):\n",
        "  total_time = end - start\n",
        "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "  return total_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMPj1JcqKLYl"
      },
      "outputs": [],
      "source": [
        "### train and test functions\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device):\n",
        "  # Put model in train mode\n",
        "  model.train()\n",
        "\n",
        "  # Setup train loss and accuracy values\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  # Loop through DataLoader batches\n",
        "  for batch, (img, label) in enumerate(dataloader):\n",
        "    # Send data to target device\n",
        "    img, label = img.to(device), label.to(device)\n",
        "\n",
        "    # 1. Forward pass, make predictions\n",
        "    pred_logits = model(img)\n",
        "\n",
        "    # 2. Calculate and accumulate loss across all batches\n",
        "    loss = loss_fn(pred_logits, label)\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate and accumulate accuracy across all batches\n",
        "    pred = pred_logits.softmax(dim=1).argmax(dim=1)\n",
        "    train_acc += pred.eq(label).sum().item()/len(label)\n",
        "\n",
        "    # Print status updates\n",
        "    if batch % 33 == 0:\n",
        "      print(f\"Looked at {batch * len(img)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  train_loss /= len(dataloader)\n",
        "  train_acc /= len(dataloader)\n",
        "\n",
        "  #print(f\"Train loss: {train_loss:.4f} | Train accuracy: {train_acc:.2f}%\")\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device):\n",
        "  # Put model in eval mode\n",
        "  model.eval()\n",
        "  # Setup test loss and test accuracy values\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  # Turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "    # Loop through DataLoader batches\n",
        "    for batch, (img, label) in enumerate(dataloader):\n",
        "      # Send data to target device\n",
        "      img, label = img.to(device), label.to(device)\n",
        "\n",
        "      # 1. Forward pass, make predictions\n",
        "      pred_logits = model(img)\n",
        "\n",
        "      # 2. Calculate and accumulate loss across all batches\n",
        "      test_loss += loss_fn(pred_logits, label).item()\n",
        "\n",
        "      # Calculate and accumulate accuracy across all batches\n",
        "      pred = pred_logits.softmax(dim=1).argmax(dim=1)\n",
        "      test_acc += pred.eq(label).sum().item()/len(label)\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    test_loss /= len(dataloader)\n",
        "    test_acc /= len(dataloader)\n",
        "\n",
        "  #print(f\"Test loss: {test_loss:.4f} | Test accuracy: {test_acc:.2f}%\")\n",
        "  return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_zwJlhZMREh"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          epochs: int,\n",
        "          device: torch.device):\n",
        "  # Create empty results dictionary\n",
        "  results = {\"train_loss\": [],\n",
        "             \"train_acc\": [],\n",
        "             \"test_loss\": [],\n",
        "             \"test_acc\": []\n",
        "             }\n",
        "\n",
        "\n",
        "  # Send model to target device\n",
        "  model.to(device)\n",
        "\n",
        "  # Loop through training and testing steps for a number of epochs\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\\n------\")\n",
        "    train_loss, train_acc = train_step(model=model,\n",
        "                                      dataloader=train_dataloader,\n",
        "                                      loss_fn=loss_fn,\n",
        "                                      optimizer=optimizer,\n",
        "                                      device=device)\n",
        "    test_loss, test_acc = test_step(model=model,\n",
        "                                    dataloader=test_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    device=device)\n",
        "\n",
        "    # Print out what's happening\n",
        "    print(\n",
        "        f\"Epoch: {epoch+1} | \"\n",
        "        f\"train_loss: {train_loss:.4f} | \"\n",
        "        f\"train_acc: {train_acc:.3f} | \"\n",
        "        f\"test_loss: {test_loss:.4f} | \"\n",
        "        f\"test_acc: {test_acc:.3f}\"\n",
        "    )\n",
        "\n",
        "    # Update results dictionary\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "  # Return the filled results at the end of the epochs\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2Jjse8ybrdL"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
        "epochs = 10\n",
        "t_start = time.time()\n",
        "res = train(model=model_0,\n",
        "            train_dataloader=train_dataloader,\n",
        "            test_dataloader=test_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            optimizer=optimizer,\n",
        "            epochs=epochs,\n",
        "            device=device)\n",
        "t_model_0 = train_time(start=t_start, end=time.time(), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2XWOjfajPEz"
      },
      "outputs": [],
      "source": [
        "# Plot loss curves of a model\n",
        "def plot_loss_curves(results):\n",
        "  loss = results[\"train_loss\"]\n",
        "  test_loss = results[\"test_loss\"]\n",
        "\n",
        "  acc = results[\"train_acc\"]\n",
        "  test_acc = results[\"test_acc\"]\n",
        "\n",
        "  epochs = range(len(results[\"train_loss\"]))\n",
        "\n",
        "  plt.figure(figsize=(15,7))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs, loss, label=\"train_loss\")\n",
        "  plt.plot(epochs, test_loss, label=\"test_loss\")\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs, acc, label=\"train_acc\")\n",
        "  plt.plot(epochs, test_acc, label=\"test_acc\")\n",
        "  plt.title(\"Accuracy\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBQU-4kCkTQn"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzfYoK9VJail"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "def make_predictions(model: torch.nn.Module,\n",
        "                     data: list,\n",
        "                     device: torch.device):\n",
        "  pred_probs = []\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      # Prepare sample\n",
        "      sample = sample.unsqueeze(dim=0).to(device) # Add an extra dimension and send sample to device\n",
        "\n",
        "      # Forward pass (model outputs raw logits)\n",
        "      pred_logit = model(sample)\n",
        "\n",
        "      # Get prediction probability (logit -> prediction probability)\n",
        "      pred_prob = pred_logit.squeeze().softmax(dim=0) # perform softmax on the \"logits\" dim, not \"batch\" dim\n",
        "\n",
        "      # Send data to cpu\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "\n",
        "  # Stack the pred_probs to turn list into a tensor\n",
        "  return torch.stack(pred_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Rdzwj4dKVOT"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_data), k=9):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "\n",
        "print(len(test_samples))\n",
        "\n",
        "# View the first test sample shape and label\n",
        "print(f\"Test sample image shape: {test_samples[0].shape}\\nTest sample label: {test_labels[0]} ({class_names[test_labels[0]]})\")\n",
        "\n",
        "# Make predictions on test samples with model_0\n",
        "pred_probs = make_predictions(model=model_0,\n",
        "                              data=test_samples,\n",
        "                              device=device)\n",
        "\n",
        "# View first two prediction probabilities list\n",
        "print(pred_probs[:2])\n",
        "\n",
        "# Turn the prediction probabilities into prediction labels by taking the argmax()\n",
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "#print(pred_classes)\n",
        "\n",
        "# Are predictions in the same form as test labels?\n",
        "print(f\"Test labels: {test_labels}\\nPredicted labels: {pred_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMUjHBBDK7bt"
      },
      "outputs": [],
      "source": [
        "# Plot predictions\n",
        "plt.figure(figsize=(9,9))\n",
        "nrows, ncols = 3, 3\n",
        "for i, sample in enumerate(test_samples):\n",
        "  # Create a subplot\n",
        "  plt.subplot(nrows, ncols, i+1)\n",
        "\n",
        "  # Plot the target image\n",
        "  plt.imshow(sample.permute(1,2,0))\n",
        "\n",
        "  # Find the prediction label\n",
        "  pred_label = class_names[pred_classes[i]]\n",
        "\n",
        "  # Get the truth label\n",
        "  truth_label = class_names[test_labels[i]]\n",
        "\n",
        "  # Create the title text of the plot\n",
        "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
        "\n",
        "  # Check for equality and change title color accordingly\n",
        "  if pred_label == truth_label:\n",
        "    plt.title(title_text, fontsize=10, c='g')\n",
        "  else:\n",
        "    plt.title(title_text, fontsize=10, c='r')\n",
        "  plt.axis(False);"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
