{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASoYK5x61j_i"
      },
      "outputs": [],
      "source": [
        "# Import PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check version\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")\n",
        "\n",
        "# Device agnostic\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "0F-7b1dw2Kwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "print(f\"image shape: {image.shape}, label shape: {label}\")\n",
        "print(f\"Train data length: {len(train_data.data)}, Train targets length: {len(train_data.targets)}\")\n",
        "print(f\"Test data length: {len(test_data.data)}, Test targets length: {len(test_data.targets)}\")\n",
        "class_names = train_data.classes\n",
        "print(f\"Class names: {class_names}\")\n",
        "plt.imshow(image.permute(1,2,0), cmap='gray')\n",
        "plt.title(class_names[label]);"
      ],
      "metadata": {
        "id": "-YII3QZt218I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot more images\n",
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows * cols + 1):\n",
        "  random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "  img, label = train_data[random_idx]\n",
        "  fig.add_subplot(rows, cols, i)\n",
        "  plt.imshow(img.squeeze(), cmap='gray')\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "niFWhYzK4j2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup the batch size hyperparameter\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Turn datasets into iterables (batches)\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Let's check out what we've created\n",
        "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
        "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
        "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")\n",
        "\n",
        "# Checkout what's inside the training dataloader\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "print(f\"Features batch shape: {train_features_batch.shape}, Labels batch shape: {train_labels_batch.shape}\")\n",
        "\n",
        "# And we can see that the data remains unchanged by checking a single sample\n",
        "# Show a sample\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.permute(1,2,0), cmap='gray')\n",
        "plt.title(class_names[label])\n",
        "plt.axis(\"Off\");\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}, label size: {label.shape}\")"
      ],
      "metadata": {
        "id": "msNo2O1O5LAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Base Model\n",
        "#create a flatten layer\n",
        "flatten_model = nn.Flatten() # all nn modules funciton as a model (can do a forward pass)\n",
        "\n",
        "# get a single sample\n",
        "x = train_features_batch[0]\n",
        "\n",
        "# flatten the sample\n",
        "output = flatten_model(x)\n",
        "\n",
        "# Print out what happened\n",
        "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Shape after flattening: {output.shape} -> [color_channels, height*width]\")\n",
        "\n",
        "#print(x)\n",
        "#print(output)"
      ],
      "metadata": {
        "id": "AhFZoAgQ7TVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTModelV0(nn.Module):\n",
        "  def __init__(self, in_shape: int, hidden_units: int, out_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=in_shape, out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units, out_features=out_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_stack(x)\n",
        "\n",
        "# Create a model with non-linear and linear layers\n",
        "class FashionMNISTModelV1(nn.Module):\n",
        "  def __init__(self, in_shape: int, hidden_units: int, out_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=in_shape, out_features=hidden_units),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_units, out_features=out_shape),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    return self.layer_stack(x)\n",
        "\n",
        "# Create a convolutional neural network\n",
        "class FashionMNISTModelV2(nn.Module):\n",
        "  def __init__(self, in_shape: int, hidden_units: int, out_shape: int):\n",
        "    super().__init__()\n",
        "    self.block1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.block2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7,\n",
        "                  out_features=out_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    return self.classifier(self.block2(self.block1(x)))"
      ],
      "metadata": {
        "id": "jy3HQlf-8FRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model_0 = FashionMNISTModelV0(in_shape=784,\n",
        "                              hidden_units=10,\n",
        "                              out_shape=len(class_names))\n",
        "model_1 = FashionMNISTModelV1(in_shape=784,\n",
        "                              hidden_units=10,\n",
        "                              out_shape=len(class_names))\n",
        "model_2 = FashionMNISTModelV2(in_shape=1,\n",
        "                              hidden_units=10,\n",
        "                              out_shape=len(class_names))\n",
        "print(model_0.to(device))\n",
        "print(f\"Model on Device: {next(model_0.parameters()).device}\")\n",
        "print(model_1.to(device))\n",
        "print(f\"Model on Device: {next(model_1.parameters()).device}\")\n",
        "print(model_2.to(device))\n",
        "print(f\"Model on Device: {next(model_2.parameters()).device}\")"
      ],
      "metadata": {
        "id": "rXLJAorT8so6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def print_train_time(start: float, end: float, device=None):\n",
        "  total_time = end - start\n",
        "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "fIzTpvgc9cU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set the seed and start the timer\n",
        "torch.manual_seed(42)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)\n",
        "\n",
        "t_start = time.time()\n",
        "\n",
        "# Set the number of epoch\n",
        "epochs = 3\n",
        "\n",
        "# Create training and testing loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n------\")\n",
        "  ### Training\n",
        "  train_loss = 0\n",
        "  model_0.to(device)\n",
        "  model_0.train()\n",
        "  # Add a loop to loop through training batches\n",
        "  for batch, (img, label) in enumerate(train_dataloader):\n",
        "    # Send data to device\n",
        "    img, label = img.to(device), label.to(device)\n",
        "    # 1. Forward pass\n",
        "    pred = model_0(img)\n",
        "\n",
        "    # 2. Calculate the loss (per batch)\n",
        "    loss = loss_fn(pred, label)\n",
        "    train_loss += loss # accumulatively add up the loss per epoch\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print out how many samples have been seen\n",
        "    if batch % 400 == 0:\n",
        "      print(f\"Looked at {batch * len(img)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "  # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
        "  train_loss /= len(train_dataloader)\n",
        "\n",
        "  ### Testing\n",
        "  # Setup variables for accumulatively adding up loss and accuracy\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    for img, label in test_dataloader:\n",
        "      # Send data to device\n",
        "      img, label = img.to(device), label.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      test_pred = model_0(img)\n",
        "\n",
        "      # 2. Calculate the loss/acc\n",
        "      test_loss += loss_fn(test_pred, label)\n",
        "      test_acc += (torch.eq(test_pred.softmax(dim=1).argmax(dim=1), label).sum().item()/len(label))*100\n",
        "\n",
        "    # Calculations on test metrics need to happen inside toch.inference_mode()\n",
        "    # Divide total test loss by length of test dataloader (per batch)\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "    # Divide total accuracy by length of test dataloader (per batch)\n",
        "    test_acc /= len(test_dataloader)\n",
        "\n",
        "  ## Print out what's heppening\n",
        "  print(f\"\\nTrain loss: {train_loss:.4f} | Test loss: {test_loss:.4f}, Test acc: {test_acc:.2f}%\\n\")\n",
        "\n",
        "  # Calculate training time\n",
        "  t_end = time.time()\n",
        "  #print(f\"Train time on {device}: {t_end-t_start:.3f} seconds\")\n",
        "train_time_model_0 = print_train_time(t_start, time.time(), device)\n"
      ],
      "metadata": {
        "id": "8vewcIMf9vcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functionizing training and test loops\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device):\n",
        "  train_loss, train_acc = 0, 0\n",
        "  model.to(device)\n",
        "  for batch, (img, label) in enumerate(dataloader):\n",
        "    # Send data to device\n",
        "    img, label = img.to(device), label.to(device)\n",
        "\n",
        "    # 1. Forward pass\n",
        "    pred = model(img)\n",
        "\n",
        "    # 2. Calculate accumulatively loss/acc\n",
        "    loss = loss_fn(pred, label)\n",
        "    train_loss += loss\n",
        "    train_acc += (torch.eq(pred.softmax(dim=1).argmax(dim=1), label).sum().item()/len(label))*100\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "  # Calculate loss and accuracy per epoch and print out what's heppening\n",
        "  train_loss /= len(dataloader)\n",
        "  train_acc /= len(dataloader)\n",
        "  print(f\"Train loss: {train_loss:.4f} | Train accuracy: {train_acc:.2f}%\")\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device):\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for batch, (img, label) in enumerate(dataloader):\n",
        "      # Send data to device\n",
        "      img, label = img.to(device), label.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      pred = model(img)\n",
        "\n",
        "      # 2. Calculate accumulatively loss/acc\n",
        "      test_loss += loss_fn(pred, label)\n",
        "      test_acc += (torch.eq(pred.softmax(dim=1).argmax(dim=1), label).sum().item()/len(label))*100\n",
        "\n",
        "    # Calculate loss and accuracy per epoch and print out what's happening\n",
        "    test_loss /= len(dataloader)\n",
        "    test_acc /= len(dataloader)\n",
        "    print(f\"Test loss: {test_loss:.4f} | Test accuracy: {test_acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "4P87lmUJGpSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "torch.manual_seed(42)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(), lr=0.1)\n",
        "\n",
        "t_start = time.time()\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n------\")\n",
        "  train_step(model=model_1,\n",
        "             dataloader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             device=device)\n",
        "  test_step(model=model_1,\n",
        "            dataloader=test_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            device=device)\n",
        "\n",
        "train_time_model_1 = print_train_time(start=t_start,\n",
        "                                      end=time.time(),\n",
        "                                      device=device)"
      ],
      "metadata": {
        "id": "WFU4zdQXLm6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "torch.manual_seed(42)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.1)\n",
        "t_start = time.time()\n",
        "\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n------\")\n",
        "  train_step(model=model_2,\n",
        "             dataloader=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             device=device)\n",
        "  test_step(model=model_2,\n",
        "            dataloader=test_dataloader,\n",
        "            loss_fn=loss_fn,\n",
        "            device=device)\n",
        "\n",
        "train_time_model_2 = print_train_time(start=t_start,\n",
        "                                      end=time.time(),\n",
        "                                      device=device)"
      ],
      "metadata": {
        "id": "X7vX4uJrVXta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Eval model\n",
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               device: torch.device):\n",
        "  loss, acc = 0, 0\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for batch, (img, label) in enumerate(dataloader):\n",
        "      # Send data to device\n",
        "      img, label = img.to(device), label.to(device)\n",
        "\n",
        "      # 1. Forward pass/ Make predictions\n",
        "      pred = model(img)\n",
        "\n",
        "      # 2. Accumulate loss and accuracy per batch\n",
        "      loss += loss_fn(pred, label)\n",
        "      acc += (torch.eq(pred.softmax(dim=1).argmax(dim=1), label).sum().item()/len(label))*100\n",
        "\n",
        "    # Scale loss/acc to find the average loss/acc per batch\n",
        "    loss /= len(dataloader)\n",
        "    acc /= len(dataloader)\n",
        "\n",
        "  return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
        "          \"model_loss\": loss.item(),\n",
        "          \"model_acc\": acc}\n"
      ],
      "metadata": {
        "id": "vXGLeDdMN5xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 0 results on test dataset\n",
        "model_0_results = eval_model(model=model_0,\n",
        "                             dataloader=test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             device=device)\n",
        "print(f\"\\nModel0 results: {model_0_results}\")\n",
        "model_1_results = eval_model(model=model_1,\n",
        "                dataloader=test_dataloader,\n",
        "                loss_fn=loss_fn,\n",
        "                device=device)\n",
        "print(f\"\\nModel1 results: {model_1_results}\")\n",
        "model_2_results = eval_model(model=model_2,\n",
        "                             dataloader=test_dataloader,\n",
        "                             loss_fn=loss_fn,\n",
        "                             device=device)\n",
        "print(f\"\\nModel2 results: {model_2_results}\")"
      ],
      "metadata": {
        "id": "0_tifIrPNLZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "compare_results = pd.DataFrame([model_0_results, model_1_results, model_2_results])\n",
        "print(compare_results)\n",
        "# Add training times to results comparison\n",
        "compare_results[\"training_time\"] = [train_time_model_0,\n",
        "                                    train_time_model_1,\n",
        "                                    train_time_model_2]\n",
        "print(compare_results)\n",
        "compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind=\"barh\")\n",
        "plt.xlabel(\"accuracy (%)\")\n",
        "plt.ylabel(\"model\");"
      ],
      "metadata": {
        "id": "sauDOEeS51uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "def make_predictions(model: torch.nn.Module,\n",
        "                     data: list,\n",
        "                     device: torch.device):\n",
        "  pred_probs = []\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      # Prepare sample\n",
        "      sample = sample.unsqueeze(dim=0).to(device) # Add an extra dimension and send sample to device\n",
        "\n",
        "      # Forward pass (model outputs raw logits)\n",
        "      pred_logit = model(sample)\n",
        "\n",
        "      # Get prediction probability (logit -> prediction probability)\n",
        "      pred_prob = pred_logit.squeeze().softmax(dim=0) # perform softmax on the \"logits\" dimension, not \"batch\" dimension (in this case we have batch size of 1, so can perform on dim=0)\n",
        "\n",
        "      # Send data to cpu\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "\n",
        "  # Stack the pred_probs to turn list into a tensor\n",
        "  return torch.stack(pred_probs)"
      ],
      "metadata": {
        "id": "V7_h7w858gON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_data), k=9):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "\n",
        "print(len(test_samples))\n",
        "\n",
        "# View the first test sample shape and label\n",
        "print(f\"Test sample image shape: {test_samples[0].shape}\\nTest sample label: {test_labels[0]} ({class_names[test_labels[0]]})\")\n",
        "\n",
        "# Make predictions on test samples with model 2\n",
        "pred_probs = make_predictions(model=model_2,\n",
        "                              data=test_samples,\n",
        "                              device=device)\n",
        "\n",
        "# View first two prediction probabilities list\n",
        "print(pred_probs[:2])\n",
        "\n",
        "# Turn the prediction probabilities into prediction labels by taking the argmax()\n",
        "pred_classes = pred_probs.argmax(dim=1)\n",
        "#print(pred_classes)\n",
        "\n",
        "# Are predictions in the same form as test labels?\n",
        "print(f\"Test labels: {test_labels}\\nPredicted labels: {pred_classes}\")"
      ],
      "metadata": {
        "id": "kzPsp84f9tQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot predictions\n",
        "plt.figure(figsize=(9,9))\n",
        "nrows, ncols = 3, 3\n",
        "for i, sample in enumerate(test_samples):\n",
        "  # Create a subplot\n",
        "  plt.subplot(nrows, ncols, i+1)\n",
        "\n",
        "  # Plot the target image\n",
        "  plt.imshow(sample.permute(1,2,0), cmap='gray')\n",
        "\n",
        "  # Find the prediction label (in text form, e.g. \"Sandal\")\n",
        "  pred_label = class_names[pred_classes[i]]\n",
        "\n",
        "  # Get the truth label (in text form, e.g. \"T-shirt\")\n",
        "  truth_label = class_names[test_labels[i]]\n",
        "\n",
        "  # Create the title text of the plot\n",
        "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
        "\n",
        "  # Check for equality and change title color accordingly\n",
        "  if pred_label == truth_label:\n",
        "    plt.title(title_text, fontsize=10, c='g') # green text if correft\n",
        "  else:\n",
        "    plt.title(title_text, fontsize=10, c='r') # red text if wrong\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "XtG4X2y0_AAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Save model\n",
        "from pathlib import Path\n",
        "\n",
        "# Create models directory (if it doesn't already exist)\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True,\n",
        "                 exist_ok=True)\n",
        "\n",
        "# Create model save path\n",
        "MODEL_NAME = \"fashion.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# Save the model state dict\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_2.state_dict(), # only saving the state_dict() only saves the learned parameters\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "RWSkcHsNGTG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new instance of Model\n",
        "loaded_model_2 = FashionMNISTModelV2(in_shape=1,\n",
        "                                    hidden_units=10,\n",
        "                                    out_shape=len(class_names))\n",
        "\n",
        "# Load in the saved state_dict()\n",
        "loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "\n",
        "# Send model to device\n",
        "loaded_model_2 = loaded_model_2.to(device)\n",
        "\n",
        "# Evaluate loaded model\n",
        "torch.manual_seed(42)\n",
        "\n",
        "loaded_model_2_results = eval_model(model=loaded_model_2,\n",
        "                                    dataloader=test_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    device=device)\n",
        "\n",
        "print(loaded_model_2_results)\n",
        "\n",
        "# Check to see if results are close to each other (if they are very far aay, there may be an error)\n",
        "close = torch.isclose(torch.tensor(model_2_results[\"model_loss\"]),\n",
        "              torch.tensor(loaded_model_2_results[\"model_loss\"]),\n",
        "              atol=1e-08,\n",
        "              rtol=0.0001)\n",
        "print(\"yes\" if close.item() else \"No\")"
      ],
      "metadata": {
        "id": "RR-Jm8jOHJAZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}