{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a1b54cce-7f2d-490c-93d8-71a3dc85bb39",
      "metadata": {
        "id": "a1b54cce-7f2d-490c-93d8-71a3dc85bb39"
      },
      "source": [
        "#  ISLES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WaPzp6sCePRY",
      "metadata": {
        "id": "WaPzp6sCePRY"
      },
      "outputs": [],
      "source": [
        "# Update APIs\n",
        "try:\n",
        "  import torch\n",
        "  import torchvision\n",
        "  assert int(torch.__version__.split(\".\")[0]) >= 2, \"torch version should be 2.0+\"\n",
        "  assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "  print(f\"torch version: {torch.__version__}\")\n",
        "  print(f\"torchvision version: {torchvision.__version__}\")\n",
        "except:\n",
        "  print(f\"[INFO] torch/torchvision versions not as required, installing new version.\")\n",
        "  !pip3 install -U --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cu121\n",
        "  import torch\n",
        "  import torchvision\n",
        "  print(f\"torch version: {torch.__version__}\")\n",
        "  print(f\"torchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0658a98d-39df-42d4-87ba-dfe488829208",
      "metadata": {
        "id": "0658a98d-39df-42d4-87ba-dfe488829208"
      },
      "outputs": [],
      "source": [
        "# regular imports\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "  !pip install -q torchinfo\n",
        "  from torchinfo import summary\n",
        "\n",
        "# Try to import utils directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "  from utils.data_setup import ISLESDataSet, create_datasets, create_dataloaders\n",
        "  from utils.plots import *\n",
        "  from utils.model_builder import *\n",
        "except:\n",
        "  # Get the utils scripts\n",
        "  print(f\"[INFO] Couldn't find utils scripts... downloading them from GitHub.\")\n",
        "  !git clone https://github.com/isijoe/isles\n",
        "  !mv isles/utils .\n",
        "  !rm -rf isles\n",
        "  from utils.data_setup import ISLESDataSet, create_datasets, create_dataloaders\n",
        "  from utils.plots import *\n",
        "  from utils.model_builder import *\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "22fc1776-0ee8-4bd8-9944-bfa9511c2b25",
      "metadata": {
        "id": "22fc1776-0ee8-4bd8-9944-bfa9511c2b25"
      },
      "source": [
        "## 1. Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HYAvT3TUilxH",
      "metadata": {
        "id": "HYAvT3TUilxH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!cp drive/MyDrive/datas/data.zip .\n",
        "!unzip -q data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2380577",
      "metadata": {
        "id": "b2380577"
      },
      "outputs": [],
      "source": [
        "# make a short check\n",
        "check = ISLESDataSet(max_size=1)\n",
        "batch, seg, patid, fid = check[0]\n",
        "print('Look at a sample dataset: ', batch.shape, seg.shape, patid, fid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc8c74c6-18e2-410e-af84-e44035aefec7",
      "metadata": {
        "id": "cc8c74c6-18e2-410e-af84-e44035aefec7"
      },
      "outputs": [],
      "source": [
        "# Create training and testing datasets\n",
        "train_ds, val_ds = create_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea715ffb",
      "metadata": {
        "id": "ea715ffb"
      },
      "outputs": [],
      "source": [
        "# Plot flair, DWI, T1, T2, and segmentation for one stratum. Output the patient ID and stratum number of the dataset.\n",
        "plot_images(train_ds[60])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "622141a4-7fd2-4673-9269-983c67446d4f",
      "metadata": {
        "id": "622141a4-7fd2-4673-9269-983c67446d4f"
      },
      "source": [
        "## 2. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b107e961",
      "metadata": {
        "id": "b107e961"
      },
      "outputs": [],
      "source": [
        "def run_iteration(dataloader, ll, do_backprob=True):\n",
        "    model, optimizer, loss_fn, device = ll[0], ll[1], ll[2], ll[3]\n",
        "    loss_iter = 0\n",
        "    for x, y, pid, sid in dataloader:\n",
        "        # Data to device\n",
        "        x, y = x.to(device), y.squeeze(dim=1).long().to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_logits = model(x) #.squeeze()\n",
        "        y_pred = y_logits.softmax(dim=1).argmax(dim=1)\n",
        "\n",
        "        #print(f\"y_logits dtype: {y_logits.dtype} | y_true dtype: {y.dtype}\")\n",
        "        #print(f\"y_logits shape: {y_logits.shape} | y_true shape: {y.shape}\")\n",
        "        # 2. Calculate the loss\n",
        "        loss = loss_fn(y_logits, y)\n",
        "\n",
        "        if do_backprob:\n",
        "            # 3. Optimizer zero grad\n",
        "            optimizer.zero_grad()\n",
        "            # 4. Loss backward\n",
        "            loss.backward()\n",
        "            # 5. Optimizer step\n",
        "            optimizer.step()\n",
        "\n",
        "        loss_iter += loss.item()\n",
        "\n",
        "    return loss_iter/len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6f789ab-763d-4b12-adf9-60e4cb3587f0",
      "metadata": {
        "id": "c6f789ab-763d-4b12-adf9-60e4cb3587f0"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "from torch import optim\n",
        "import time\n",
        "\n",
        "# set a flag which device to use ('cpu' or 'cuda', according to availability)\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = 'mps'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# define training hyperparameters\n",
        "batch_size = 32\n",
        "num_epochs = 50  # later use 100 - 500 Epochs\n",
        "lr = 0.001\n",
        "\n",
        "# initializations\n",
        "model = ISLESSegNet().to(device)\n",
        "model = torch.compile(model)\n",
        "#model = UNet(4,2).to(device)\n",
        "#model = torch.compile(model, backend=\"aot_eager\") # aot_eager for mps\n",
        "\n",
        "# uncomment for retraining previous model\n",
        "#chkpt_file = '/content/checkpoints/isles01.pt'\n",
        "#model.load_state_dict(torch.load(chkpt_file))\n",
        "\n",
        "# CrossEntropyLoss works fine\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# BCEWithLogitsLoss\n",
        "#loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# DiceLoss achieved minimal better results and has less overfitting: Training 80.84%, Testing 72.44% (see Figure in last cell)\n",
        "#loss_fn = DiceLoss(include_background=False)\n",
        "\n",
        "#optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Adam optimizer much better testing Dice???: Training 69.01%, Testing 75.28% (see Figure in last cell)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "ll = [model, optimizer, loss_fn, device]\n",
        "tdl, vdl = create_dataloaders(train_ds, val_ds, batch_size=batch_size)\n",
        "is_better = True\n",
        "prev_loss = [float('inf'), float('inf')]\n",
        "\n",
        "epoch_loss = torch.zeros(num_epochs)\n",
        "val_loss = torch.zeros(num_epochs)\n",
        "save_path = \"checkpoints\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "# start timer for full training\n",
        "t_end = time.time()\n",
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # start timer for epoch\n",
        "    t_start = time.time()\n",
        "    print('Epoch {} from {}'.format(epoch+1, num_epochs))\n",
        "\n",
        "    model.train()\n",
        "    epoch_loss[epoch] = run_iteration(tdl, ll)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        val_loss[epoch] = run_iteration(vdl, ll, do_backprob=False)\n",
        "\n",
        "        delta_epoch = time.time() - t_start\n",
        "\n",
        "        # print the current epoch's training and validation mean loss\n",
        "        print('[{}] Training loss: {:.4f}'.format(epoch+1, epoch_loss[epoch]))\n",
        "        print('[{}] Validation Loss: {:.4f}\\t Time: {:.2f}s'.format(epoch+1, val_loss[epoch], delta_epoch))\n",
        "\n",
        "        # check if current epoch's losses are better then best saved\n",
        "        is_better = epoch_loss[epoch] < prev_loss[0] and val_loss[epoch] <= prev_loss[1]\n",
        "        if is_better:\n",
        "            # update best training and validation losses\n",
        "            prev_loss[0] = epoch_loss[epoch]\n",
        "            prev_loss[1] = val_loss[epoch]\n",
        "            # save best model\n",
        "        if epoch > 15:\n",
        "            torch.save(model.state_dict(), './checkpoints/isles01.pt')\n",
        "            print(\"\\033[91m {}\\033[00m\" .format(\"Saved best model\"))\n",
        "t_end = time.time() - t_end\n",
        "print('Finished Training in {:.2f} seconds'.format(t_end))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85cf1a40",
      "metadata": {
        "id": "85cf1a40"
      },
      "outputs": [],
      "source": [
        "# save manually\n",
        "torch.save(model.state_dict(), './checkpoints/isles01.pt')\n",
        "print(\"\\033[91m {}\\033[00m\" .format(\"Saved best model\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eaccc02-68c7-47ba-aabe-2f8aa9e24d39",
      "metadata": {
        "id": "8eaccc02-68c7-47ba-aabe-2f8aa9e24d39"
      },
      "outputs": [],
      "source": [
        "# visualize the losses\n",
        "plot_loss(epoch_loss, val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83742dfa",
      "metadata": {
        "id": "83742dfa"
      },
      "outputs": [],
      "source": [
        "# plot prediction and ground trouth\n",
        "plot_pred(model, train_ds[66], device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
