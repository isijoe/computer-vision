{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1b54cce-7f2d-490c-93d8-71a3dc85bb39",
   "metadata": {},
   "source": [
    "#  ISLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0658a98d-39df-42d4-87ba-dfe488829208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from utils.data_setup import ISLESDataSet, CreateDataSets\n",
    "from utils.plots import *\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22fc1776-0ee8-4bd8-9944-bfa9511c2b25",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2380577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a short check\n",
    "check = ISLESDataSet(max_size=1)\n",
    "batch, seg, patid, fid = check[0]\n",
    "print('Look at a sample dataset: ', batch.shape, seg.shape, patid, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8c74c6-18e2-410e-af84-e44035aefec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing datasets\n",
    "train_ds, val_ds = CreateDataSets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea715ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot flair, DWI, T1, T2, and segmentation for one stratum. Output the patient ID and stratum number of the dataset.\n",
    "plot_images(train_ds[60])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "622141a4-7fd2-4673-9269-983c67446d4f",
   "metadata": {},
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b107e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iteration(dataloader, ll, do_backprob=True):\n",
    "    model, optimizer, loss_fn, device = ll[0], ll[1], ll[2], ll[3]\n",
    "    loss_iter = 0\n",
    "    for x, y, pid, sid in dataloader:\n",
    "        # Data to device\n",
    "        x, y = x.to(device), y.squeeze(dim=1).long().to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_logits = model(x) #.squeeze()\n",
    "        y_pred = y_logits.softmax(dim=1).argmax(dim=1)\n",
    "\n",
    "        #print(f\"y_logits dtype: {y_logits.dtype} | y_true dtype: {y.dtype}\")\n",
    "        #print(f\"y_logits shape: {y_logits.shape} | y_true shape: {y.shape}\")\n",
    "        # 2. Calculate the loss\n",
    "        loss = loss_fn(y_logits, y)\n",
    "\n",
    "        if do_backprob:\n",
    "            # 3. Optimizer zero grad\n",
    "            optimizer.zero_grad()\n",
    "            # 4. Loss backward\n",
    "            loss.backward()\n",
    "            # 5. Optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "        loss_iter += loss.item()\n",
    "      \n",
    "    return loss_iter/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f789ab-763d-4b12-adf9-60e4cb3587f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from model_builder import *\n",
    "\n",
    "# set a flag which device to use ('cpu' or 'cuda', according to availability)\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# define training hyperparameters\n",
    "batch_size = 32\n",
    "num_epochs = 20  # later use 100 - 500 Epochs\n",
    "lr = 0.1\n",
    "\n",
    "# initializations\n",
    "model = ISLESSegNet().to(device)\n",
    "#model = UNet(4,2).to(device)\n",
    "#model = torch.compile(model, backend=\"aot_eager\") # aot_eager for mps\n",
    "\n",
    "# uncomment for retraining previous model\n",
    "#chkpt_file = '/content/checkpoints/isles01.pt'\n",
    "#model.load_state_dict(torch.load(chkpt_file))\n",
    "\n",
    "# CrossEntropyLoss works fine\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# BCEWithLogitsLoss\n",
    "#loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# DiceLoss achieved minimal better results and has less overfitting: Training 80.84%, Testing 72.44% (see Figure in last cell) \n",
    "#loss_fn = DiceLoss(include_background=False)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Adam optimizer much better testing Dice???: Training 69.01%, Testing 75.28% (see Figure in last cell)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "ll = [model, optimizer, loss_fn, device]\n",
    "tdl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "vdl = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "is_better = True\n",
    "prev_loss = [float('inf'), float('inf')]\n",
    "\n",
    "epoch_loss = torch.zeros(num_epochs)\n",
    "val_loss = torch.zeros(num_epochs)\n",
    "save_path = \"checkpoints\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "# start timer for full training\n",
    "t_end = time.time()\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # start timer for epoch\n",
    "    t_start = time.time()\n",
    "    print('Epoch {} from {}'.format(epoch+1, num_epochs))\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss[epoch] = run_iteration(tdl, ll)\n",
    "  \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        val_loss[epoch] = run_iteration(vdl, ll, do_backprob=False)\n",
    "\n",
    "        delta_epoch = time.time() - t_start\n",
    "        \n",
    "        # print the current epoch's training and validation mean loss\n",
    "        print('[{}] Training loss: {:.4f}'.format(epoch+1, epoch_loss[epoch]))\n",
    "        print('[{}] Validation Loss: {:.4f}\\t Time: {:.2f}s'.format(epoch+1, val_loss[epoch], delta_epoch))\n",
    "\n",
    "        # check if current epoch's losses are better then best saved\n",
    "        is_better = epoch_loss[epoch] < prev_loss[0] and val_loss[epoch] <= prev_loss[1]\n",
    "        if is_better:\n",
    "            # update best training and validation losses\n",
    "            prev_loss[0] = epoch_loss[epoch]\n",
    "            prev_loss[1] = val_loss[epoch]\n",
    "            # save best model\n",
    "        if epoch > 15:\n",
    "            torch.save(model.state_dict(), './checkpoints/isles01.pt')\n",
    "            print(\"\\033[91m {}\\033[00m\" .format(\"Saved best model\"))\n",
    "t_end = time.time() - t_end\n",
    "print('Finished Training in {:.2f} seconds'.format(t_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf1a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save manually\n",
    "torch.save(model.state_dict(), './checkpoints/isles01.pt')\n",
    "print(\"\\033[91m {}\\033[00m\" .format(\"Saved best model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaccc02-68c7-47ba-aabe-2f8aa9e24d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the losses\n",
    "plot_loss(epoch_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83742dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot prediction and ground trouth\n",
    "plot_pred(model, train_ds[55], device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
